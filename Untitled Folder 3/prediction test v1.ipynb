{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import keras.models\n",
    "from keras.models import Model\n",
    "from pybittrex.client import Client\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import model_from_json\n",
    "from keras.models import model_from_yaml\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "\n",
    "\n",
    "'''----------------------------------------Data Structurs---------------------------------------------------'''\n",
    "\n",
    "c = Client(api_key='abc', api_secret='123')\n",
    "\n",
    "depth =100\n",
    "OrderBookDepth     = 100\n",
    "MarketHistoryDepth = 100\n",
    "\n",
    "\n",
    "MarketHistory_Price=[]\n",
    "MarketHistory_Quantity=[]\n",
    "MarketHistory_FillType_Z = [] #ZERO encodecd\n",
    "MarketHistory_OrderType_Z = []\n",
    "\n",
    "OrderBook_buy_Quantity = []\n",
    "OrderBook_buy_Rate = []\n",
    "OrderBook_sell_Quantity = []\n",
    "OrderBook_sell_Rate = []\n",
    "\n",
    "Tick_Ask = []\n",
    "Tick_Bid = []\n",
    "Tick_Last = []\n",
    "\n",
    "n = 0\n",
    "\n",
    "global Prediction_Input\n",
    "\n",
    "markets_data     = {}\n",
    "\n",
    "list_of_market_stat_data = {}\n",
    "\n",
    "market_stat_data ={\"Market\"        : \"cc\",\n",
    "                   \"Tick\"          : \"cc\",\n",
    "                   \"OrderBook\"     : \"cc\",\n",
    "                   \"MarketHistory\" : \"cc\" }\n",
    "\n",
    "\n",
    "\n",
    "market_list = [\n",
    "'USDT-BTC'\n",
    "]\n",
    "\n",
    "'''------------------------------------------model loading ---------------------------------------------------'''\n",
    "model2m  = load_model('pridic2min.h5')\n",
    "model4m  = load_model('pridic4min.h5')\n",
    "model10m = load_model('pridic10min.h5')\n",
    "#model14m = load_model('pridic14min.h5')\n",
    "#model20m = load_model('pridic20min.h5')\n",
    "#model30m = load_model('pridic30min.h5')\n",
    "#model1h  = load_model('pridic1h.h5')\n",
    "#model2h  = load_model('pridic2h.h5')\n",
    "#model3h  = load_model('pridic3h.h5')\n",
    "#model4h  = load_model('pridic4h.h5')\n",
    "#model8h  = load_model('pridic8h.h5')\n",
    "#model16h  = load_model('pridic16h.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''--------------------------------------------Get Data------------------------------------------------------'''\n",
    "'''    \n",
    "for market in market_list :\n",
    "    markets_data[market] = []\n",
    "'''         \n",
    "              \n",
    "    \n",
    "def Get_market_stat_data():\n",
    "    global MarketHistory_Price\n",
    "    global MarketHistory_Quantity\n",
    "    global MarketHistory_FillType_Z \n",
    "    global MarketHistory_OrderType_Z \n",
    "    global OrderBook_buy_Quantity \n",
    "    global OrderBook_buy_Rate \n",
    "    global OrderBook_sell_Quantity \n",
    "    global OrderBook_sell_Rate\n",
    "    global Tick_Ask\n",
    "    global Tick_Bid \n",
    "    global Tick_Last\n",
    "    MarketHistory_PriceT = []\n",
    "    MarketHistory_QuantityT = []\n",
    "    MarketHistory_FillType_ZT = []\n",
    "    MarketHistory_OrderType_ZT = []\n",
    "    OrderBook_buy_QuantityT = []\n",
    "    OrderBook_buy_RateT = []\n",
    "    OrderBook_sell_QuantityT = [] \n",
    "    OrderBook_sell_RateT = []\n",
    "    Tick_AskT = []\n",
    "    Tick_BidT = []\n",
    "    Tick_LastT = []\n",
    "    market_stat_data ={\"Market\"        : \"cc\",\n",
    "                   \"Tick\"          : \"cc\",\n",
    "                   \"OrderBook\"     : \"cc\",\n",
    "                   \"MarketHistory\" : \"cc\" } \n",
    "    \n",
    "    for market in market_list:\n",
    "        market_stat_data[\"Tick\"] = (c.get_ticker(market).json())\n",
    "        market_stat_data[\"OrderBook\"] = (c.get_orderbook(market , \"both\").json())\n",
    "        market_stat_data[\"MarketHistory\"] = (c.get_market_history(market).json())\n",
    "        \n",
    "        market_stat_data[\"OrderBook\"]['result']['buy'] = market_stat_data[\"OrderBook\"]['result'][\"buy\"][:OrderBookDepth] # lemting ordebook buy depth \n",
    "        market_stat_data[\"OrderBook\"]['result']['sell'] = market_stat_data[\"OrderBook\"]['result'][\"sell\"][:OrderBookDepth] # lemting ordebook sell depth   # i discuverd a bug  here i was wrting back the market sell order book to the market buy order book no lemting it all gatherd data befor 29/11/2017 7 pm are corupted      \n",
    "        market_stat_data['MarketHistory']['result'] = market_stat_data['MarketHistory']['result'][:MarketHistoryDepth] # lemting MarketHistory depth \n",
    "    \n",
    "    markets_data[market] = (market_stat_data.copy())\n",
    "    Tick_AskT.append(market_stat_data['Tick'] ['result'] ['Ask'])\n",
    "    Tick_BidT.append(market_stat_data['Tick'] ['result'] ['Bid'])\n",
    "    Tick_LastT.append(market_stat_data['Tick'] ['result'] ['Last'])\n",
    "        \n",
    "    for m in range(len((market_stat_data['OrderBook']['result']['buy']))) :\n",
    "        OrderBook_buy_QuantityT.append(market_stat_data['OrderBook']['result']['buy'][m]['Quantity'])\n",
    "        OrderBook_buy_RateT.append(market_stat_data['OrderBook']['result']['buy'][m]['Rate'])\n",
    "       \n",
    "    for m in range(len((market_stat_data['OrderBook']['result']['sell']))) :\n",
    "        OrderBook_sell_QuantityT.append(market_stat_data['OrderBook']['result']['sell'][m]['Quantity'])\n",
    "        OrderBook_sell_RateT.append(market_stat_data['OrderBook']['result']['sell'][m]['Rate'])\n",
    " \n",
    "    for m in range(len((market_stat_data['MarketHistory']['result']))) :                                                                            \n",
    "        MarketHistory_PriceT.append(market_stat_data['MarketHistory']['result'][m]['Price'])\n",
    "        MarketHistory_QuantityT.append(market_stat_data['MarketHistory']['result'][m]['Quantity'])\n",
    "                                              \n",
    "        if (market_stat_data['MarketHistory']['result'][m]['FillType']) == 'PARTIAL_FILL' :\n",
    "            MarketHistory_FillType_ZT.append(0)\n",
    "        elif (market_stat_data['MarketHistory']['result'][m]['FillType']) == 'FILL' :\n",
    "            MarketHistory_FillType_ZT.append(1)\n",
    "        if (market_stat_data['MarketHistory']['result'][m]['OrderType']) == 'BUY' :\n",
    "            MarketHistory_OrderType_ZT.append(0)\n",
    "        elif (market_stat_data['MarketHistory']['result'][m]['OrderType']) == 'SELL' :\n",
    "            MarketHistory_OrderType_ZT.append(1)  #you have to empty it at the end of the function  \n",
    "            \n",
    "    MarketHistory_Price1=np.reshape( MarketHistory_PriceT, (depth,int(len(MarketHistory_PriceT)/depth)))\n",
    "    MarketHistory_Quantity1=np.reshape(MarketHistory_QuantityT, (depth,int(len(MarketHistory_QuantityT)/depth)))\n",
    "    MarketHistory_FillType_Z1=np.reshape(MarketHistory_FillType_ZT, (depth,int(len(MarketHistory_FillType_ZT)/depth)))\n",
    "    MarketHistory_OrderType_Z1=np.reshape(MarketHistory_OrderType_ZT, (depth,int(len(MarketHistory_OrderType_ZT)/depth)))\n",
    "    OrderBook_buy_Quantity1=np.reshape(OrderBook_buy_QuantityT, (depth,int(len(OrderBook_buy_QuantityT)/depth)))\n",
    "    OrderBook_buy_Rate1=np.reshape(OrderBook_buy_RateT, (depth,int(len(OrderBook_buy_RateT)/depth)))\n",
    "    OrderBook_sell_Quantity1=np.reshape(OrderBook_sell_QuantityT, (depth,int(len(OrderBook_sell_QuantityT)/depth)))\n",
    "    OrderBook_sell_Rate1=np.reshape(OrderBook_sell_RateT, (depth,int(len(OrderBook_sell_RateT)/depth)))\n",
    "    \n",
    "    Tick_Ask = Tick_AskT\n",
    "    \n",
    "    Tick_Ask1 =np.reshape(Tick_AskT ,(1,int(len(Tick_AskT))))\n",
    "    Tick_Bid1 =np.reshape(Tick_BidT ,(1,int(len(Tick_BidT))))\n",
    "    Tick_Last1=np.reshape(Tick_LastT ,(1,int(len(Tick_LastT))))\n",
    "    \n",
    "    Prediction_Input = np.concatenate((\n",
    "                   MarketHistory_Price1,\n",
    "                   MarketHistory_Quantity1,\n",
    "                   MarketHistory_FillType_Z1,\n",
    "                   MarketHistory_OrderType_Z1,\n",
    "                   OrderBook_buy_Quantity1,\n",
    "                   OrderBook_buy_Rate1,\n",
    "                   OrderBook_sell_Quantity1,\n",
    "                   OrderBook_sell_Rate1\n",
    "                  ))\n",
    "    Current_price = np.concatenate((\n",
    "                   Tick_Ask1,\n",
    "                   Tick_Bid1,\n",
    "                   Tick_Last1\n",
    "                  ))\n",
    "    \n",
    "    scalerCurrent_price = MinMaxScaler(feature_range=(0, 1))\n",
    "    Traning_Output_Normalized =scalerCurrent_price.fit_transform(Current_price)\n",
    "    \n",
    "    scalertraininput = MinMaxScaler(feature_range=(0, 1))\n",
    "    Prediction_Input_Normalized =scalertraininput.fit_transform(Prediction_Input)\n",
    "    \n",
    "    Prediction_Input_Normalized = np.reshape(Prediction_Input_Normalized, (Prediction_Input_Normalized.shape[1],1, Prediction_Input_Normalized.shape[0]))\n",
    "\n",
    "    \n",
    "    Prediction2m  = model2m.predict(Prediction_Input_Normalized)\n",
    "    Prediction4m  = model4m.predict(Prediction_Input_Normalized)\n",
    "    Prediction10m = model10m.predict(Prediction_Input_Normalized)\n",
    "    #Prediction14m = model14m.predict(Prediction_Input_Normalized)\n",
    "    #Prediction20m = model20m.predict(Prediction_Input_Normalized)\n",
    "    #Prediction30m = model30m.predict(Prediction_Input_Normalized)\n",
    "    #Prediction1h  = model1h.predict(Prediction_Input_Normalized)\n",
    "    #Prediction2h  = model2h.predict(Prediction_Input_Normalized)\n",
    "    #Prediction3h  = model3h.predict(Prediction_Input_Normalized)\n",
    "    #Prediction4h  = model4h.predict(Prediction_Input_Normalized)\n",
    "    #Prediction8h  = model8h.predict(Prediction_Input_Normalized)\n",
    "    #Prediction16h = model16h.predict(Prediction_Input_Normalized)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    Prediction2m = np.reshape(Prediction2m, (Prediction2m.shape[0], Prediction2m.shape[1]))\n",
    "    Prediction_UN2m =scalerCurrent_price.inverse_transform(Prediction2m)\n",
    "    \n",
    "    Prediction4m = np.reshape(Prediction4m, (Prediction4m.shape[0], Prediction4m.shape[1]))\n",
    "    Prediction_UN4m =scalerCurrent_price.inverse_transform(Prediction4m)\n",
    "    \n",
    "    Prediction10m = np.reshape(Prediction10m, (Prediction10m.shape[0], Prediction10m.shape[1]))\n",
    "    Prediction_UN10m =scalerCurrent_price.inverse_transform(Prediction10m)\n",
    "    \n",
    "    #Prediction14m = np.reshape(Prediction14m, (Prediction14m.shape[0], Prediction14m.shape[1]))\n",
    "    #Prediction_UN14m =scalerCurrent_price.inverse_transform(Prediction14m)\n",
    "    \n",
    "    #Prediction20m = np.reshape(Prediction20m, (Prediction20m.shape[0], Prediction20m.shape[1]))\n",
    "    #Prediction_UN20m =scalerCurrent_price.inverse_transform(Prediction20m)\n",
    "    \n",
    "    #Prediction30m = np.reshape(Prediction30m, (Prediction30m.shape[0], Prediction30m.shape[1]))\n",
    "    #Prediction_UN30m =scalerCurrent_price.inverse_transform(Prediction30m)\n",
    "    \n",
    "    #Prediction1h = np.reshape(Prediction1h, (Prediction1h.shape[0], Prediction1h.shape[1]))\n",
    "    #Prediction_UN1h =scalerCurrent_price.inverse_transform(Prediction1h)\n",
    "    \n",
    "    #Prediction2h = np.reshape(Prediction2h, (Prediction2h.shape[0], Prediction2h.shape[1]))\n",
    "    #Prediction_UN2h =scalerCurrent_price.inverse_transform(Prediction2h)\n",
    "    \n",
    "    #Prediction3h = np.reshape(Prediction3h, (Prediction3h.shape[0], Prediction3h.shape[1]))\n",
    "    #Prediction_UN3h =scalerCurrent_price.inverse_transform(Prediction3h)\n",
    "    \n",
    "    #Prediction4h = np.reshape(Prediction4h, (Prediction4h.shape[0], Prediction4h.shape[1]))\n",
    "    #Prediction_UN4h =scalerCurrent_price.inverse_transform(Prediction4h)\n",
    "    \n",
    "    #Prediction8h = np.reshape(Prediction8h, (Prediction8h.shape[0], Prediction8h.shape[1]))\n",
    "    #Prediction_UN8h =scalerCurrent_price.inverse_transform(Prediction8h)\n",
    "    \n",
    "    #Prediction16h = np.reshape(Prediction16h, (Prediction16h.shape[0], Prediction16h.shape[1]))\n",
    "    #Prediction_UN16h =scalerCurrent_price.inverse_transform(Prediction16h)\n",
    "    \n",
    "\n",
    "    Prediction_UN2m  = np.reshape(Prediction_UN2m,  (Prediction_UN2m.shape[1] , Prediction_UN2m.shape[0])) \n",
    "    Prediction_UN4m  = np.reshape(Prediction_UN4m,  (Prediction_UN4m.shape[1] , Prediction_UN4m.shape[0]))\n",
    "    Prediction_UN10m = np.reshape(Prediction_UN10m, (Prediction_UN10m.shape[1], Prediction_UN10m.shape[0]))\n",
    "    #Prediction_UN14m = np.reshape(Prediction_UN14m, (Prediction_UN14m.shape[1], Prediction_UN14m.shape[0]))\n",
    "    #Prediction_UN20m = np.reshape(Prediction_UN20m, (Prediction_UN20m.shape[1], Prediction_UN20m.shape[0]))\n",
    "    #Prediction_UN30m = np.reshape(Prediction_UN30m, (Prediction_UN30m.shape[1], Prediction_UN30m.shape[0]))\n",
    "    #Prediction_UN1h  = np.reshape(Prediction_UN1h,  (Prediction_UN1h.shape[1] , Prediction_UN1h.shape[0]))\n",
    "    #Prediction_UN2h  = np.reshape(Prediction_UN2h,  (Prediction_UN2h.shape[1] , Prediction_UN2h.shape[0]))\n",
    "    #Prediction_UN3h  = np.reshape(Prediction_UN3h,  (Prediction_UN3h.shape[1] , Prediction_UN3h.shape[0]))\n",
    "    #Prediction_UN4h  = np.reshape(Prediction_UN4h,  (Prediction_UN4h.shape[1] , Prediction_UN4h.shape[0]))\n",
    "    #Prediction_UN8h  = np.reshape(Prediction_UN8h,  (Prediction_UN8h.shape[1] , Prediction_UN8h.shape[0]))\n",
    "    #Prediction_UN16h = np.reshape(Prediction_UN16h, (Prediction_UN16h.shape[1], Prediction_UN16h.shape[0]))\n",
    "\n",
    "    \n",
    "    \n",
    "    Eval_mat = np.concatenate((\n",
    "                   Current_price,\n",
    "                   Prediction_UN2m,\n",
    "                   Prediction_UN4m,\n",
    "                   Prediction_UN10m\n",
    "                  ))\n",
    "    \n",
    "    Eval_mat_list= Eval_mat.tolist()\n",
    "    global n \n",
    "    for market in market_list:\n",
    "\n",
    "        with open(\"{}_Market_predictions.txt\".format(market), \"a+\") as market_file :\n",
    "              json.dump(Eval_mat_list, market_file)\n",
    "              market_file.write(\"\\n\") #padding the jason object in file with a newline indcator \"evey opject in his owen line\"\n",
    "              market_file.close()\n",
    "        print(\"Got prdiction no. {}\". format (n))\n",
    "        n = n+1\n",
    "    \n",
    "    #print(\"pp {}\".format(Prediction_UN2m))\n",
    "    #print(\"cp {}\".format(Current_price))\n",
    "    #return Eval_mat\n",
    "\n",
    "'''\n",
    "    \n",
    "Eval_mat = np.concatenate((\n",
    "                   Current_price,\n",
    "                   Prediction_UN2m,\n",
    "                   Prediction_UN4m,\n",
    "                   Prediction_UN10m,\n",
    "                   Prediction_UN14m,\n",
    "                   Prediction_UN20m,\n",
    "                   Prediction_UN30m,\n",
    "                   Prediction_UN1h,\n",
    "                   Prediction_UN2h,\n",
    "                   Prediction_UN3h,\n",
    "                   Prediction_UN4h,\n",
    "                   Prediction_UN8h,\n",
    "                   Prediction_UN16h\n",
    "                  ))    \n",
    "    \n",
    "'''\n",
    "\n",
    "'''-----------------------------------------schedular and main entry point--------------------------------------'''\n",
    "for i in range(10):\n",
    "    Get_market_stat_data() #just so i dont waist the first 2 min\n",
    "\n",
    "\n",
    "'''\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\tscheduler = BlockingScheduler()\n",
    "\tscheduler.add_job(Get_market_stat_data, 'interval', seconds=60)\n",
    "\n",
    "\ttry:\n",
    "\t\tscheduler.start()\n",
    "\texcept (KeyboardInterrupt, SystemExit):\n",
    "        \tpass                       \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''--------------------------------------------mesilinous junk------------------------------------------------------'''\n",
    "\n",
    "\n",
    "'''\n",
    "trainPredict = model.predict(traininputM)\n",
    "testPredict = model.predict(testinputM)\n",
    "\n",
    "\n",
    "\n",
    "trainPredict = np.reshape(trainPredict, (trainoutput.shape[0], trainoutput.shape[1]))\n",
    "testPredict = np.reshape(testPredict, (testoutput.shape[0], testoutput.shape[1]))\n",
    "trainoutputM = np.reshape(trainoutputM, (trainoutput.shape[0], trainoutput.shape[1]))\n",
    "testoutputM = np.reshape(testoutputM, (testoutput.shape[0], testoutput.shape[1]))\n",
    "\n",
    "trainPredict=scalertrainoutput.inverse_transform(trainoutputM)\n",
    "testPredict=scalertestoutput.inverse_transform(testPredict)\n",
    "trainoutputM=scalertrainoutput.inverse_transform(trainoutputM)\n",
    "testoutputM=scalertestoutput.inverse_transform(testoutputM)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Current_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.reshape(x, (x.shape[1], x.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_data = []\n",
    "with open(\"USDT-BTC_Market_predictions.txt\") as file :\n",
    "    for line in file:\n",
    "        json_data.append(json.loads(line))\n",
    "\n",
    "#ex: json_data[1][\"MarketHistory\"]['result']        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data[2][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
