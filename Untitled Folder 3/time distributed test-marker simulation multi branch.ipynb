{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prdiction_data_depth aday is 720 point 100 \n",
      "\n",
      "#-------prediction no. 1 the format is ASK-BID-LAST-----# \n",
      "\n",
      "Current price [ 10050.          10045.80457172  10050.        ] \n",
      "\n",
      "prediction+4min [ 10047.1171875   10046.52050781  10047.30273438] \n",
      "\n",
      "#-------------------------------------------------------------------------#\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 110), ('y', 100)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 110), ('y', 100)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 110), ('y', 100)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 110), ('y', 100)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prdiction_data_depth aday is 720 point 202 \n",
      "\n",
      "#-------prediction no. 2 the format is ASK-BID-LAST-----# \n",
      "\n",
      "Current price [ 9850.00000001  9825.765       9850.00000001] \n",
      "\n",
      "prediction+4min [ 9833.34765625  9829.89746094  9844.7578125 ] \n",
      "\n",
      "#-------------------------------------------------------------------------#\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 112), ('y', 102)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 112), ('y', 102)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 112), ('y', 102)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 112), ('y', 102)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prdiction_data_depth aday is 720 point 306 \n",
      "\n",
      "#-------prediction no. 3 the format is ASK-BID-LAST-----# \n",
      "\n",
      "Current price [ 10036.90999997  10030.          10036.90999997] \n",
      "\n",
      "prediction+4min [ 10035.41992188  10030.84570312  10034.15625   ] \n",
      "\n",
      "#-------------------------------------------------------------------------#\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 114), ('y', 104)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 114), ('y', 104)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 114), ('y', 104)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 114), ('y', 104)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prdiction_data_depth aday is 720 point 412 \n",
      "\n",
      "#-------prediction no. 4 the format is ASK-BID-LAST-----# \n",
      "\n",
      "Current price [ 9970.  9950.  9950.] \n",
      "\n",
      "prediction+4min [ 9956.25878906  9953.41015625  9960.81933594] \n",
      "\n",
      "#-------------------------------------------------------------------------#\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 116), ('y', 106)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 116), ('y', 106)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 116), ('y', 106)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 116), ('y', 106)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prdiction_data_depth aday is 720 point 520 \n",
      "\n",
      "#-------prediction no. 5 the format is ASK-BID-LAST-----# \n",
      "\n",
      "Current price [ 10021.    10010.98  10010.98] \n",
      "\n",
      "prediction+4min [ 10014.11621094  10012.68847656  10014.42089844] \n",
      "\n",
      "#-------------------------------------------------------------------------#\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 118), ('y', 108)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 118), ('y', 108)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 118), ('y', 108)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 118), ('y', 108)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prdiction_data_depth aday is 720 point 630 \n",
      "\n",
      "#-------prediction no. 6 the format is ASK-BID-LAST-----# \n",
      "\n",
      "Current price [ 10129.7  10120.   10129.7] \n",
      "\n",
      "prediction+4min [ 10127.60839844  10121.1875      10123.46289062] \n",
      "\n",
      "#-------------------------------------------------------------------------#\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 120), ('y', 110)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 120), ('y', 110)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 120), ('y', 110)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 120), ('y', 110)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prdiction_data_depth aday is 720 point 700 \n",
      "\n",
      "#-------prediction no. 7 the format is ASK-BID-LAST-----# \n",
      "\n",
      "Current price [ 10100.010005  10100.01      10100.010005] \n",
      "\n",
      "prediction+4min [ 10100.00976562  10100.00976562  10100.00976562] \n",
      "\n",
      "#-------------------------------------------------------------------------#\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 122), ('y', 112)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 122), ('y', 112)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 122), ('y', 112)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 122), ('y', 112)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prdiction_data_depth aday is 720 point 700 \n",
      "\n",
      "#-------prediction no. 8 the format is ASK-BID-LAST-----# \n",
      "\n",
      "Current price [ 9947.99        9944.94699307  9947.99      ] \n",
      "\n",
      "prediction+4min [ 9945.89941406  9946.51660156  9947.33203125] \n",
      "\n",
      "#-------------------------------------------------------------------------#\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 124), ('y', 114)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 124), ('y', 114)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 124), ('y', 114)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 124), ('y', 114)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prdiction_data_depth aday is 720 point 700 \n",
      "\n",
      "#-------prediction no. 9 the format is ASK-BID-LAST-----# \n",
      "\n",
      "Current price [ 9994.05944134  9959.          9959.        ] \n",
      "\n",
      "prediction+4min [ 9969.97363281  9964.97949219  9977.96777344] \n",
      "\n",
      "#-------------------------------------------------------------------------#\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 126), ('y', 116)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 126), ('y', 116)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 126), ('y', 116)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 126), ('y', 116)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prdiction_data_depth aday is 720 point 700 \n",
      "\n",
      "#-------prediction no. 10 the format is ASK-BID-LAST-----# \n",
      "\n",
      "Current price [ 9998.9         9994.05944133  9998.9       ] \n",
      "\n",
      "prediction+4min [ 9995.57421875  9994.88476562  9997.02734375] \n",
      "\n",
      "#-------------------------------------------------------------------------#\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 128), ('y', 118)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 128), ('y', 118)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 128), ('y', 118)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 128), ('y', 118)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prdiction_data_depth aday is 720 point 700 \n",
      "\n",
      "#-------prediction no. 11 the format is ASK-BID-LAST-----# \n",
      "\n",
      "Current price [ 10000.           9999.84190002  10000.        ] \n",
      "\n",
      "prediction+4min [ 9999.89160156  9999.86914062  9999.96582031] \n",
      "\n",
      "#-------------------------------------------------------------------------#\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 130), ('y', 120)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 130), ('y', 120)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 130), ('y', 120)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n",
      "/home/mohammed/python-vlenv/keras-tf/lib/python3.5/site-packages/bokeh/models/sources.py:137: BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 130), ('y', 120)\n",
      "  \"Current lengths: %s\" % \", \".join(sorted(str((k, len(v))) for k, v in data.items())), BokehUserWarning))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d79fe3b66cfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import keras.models\n",
    "from keras.models import Model\n",
    "from pybittrex.client import Client\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import model_from_json\n",
    "from keras.models import model_from_yaml\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "\n",
    "import timeit\n",
    "import schedule\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "'''----------------------------------------Data Structurs---------------------------------------------------'''\n",
    "\n",
    "c = Client(api_key='abc', api_secret='123')\n",
    "\n",
    "depth =10\n",
    "OrderBookDepth     = 10\n",
    "MarketHistoryDepth = 10\n",
    "\n",
    "\n",
    "MarketHistory_Price=[]\n",
    "MarketHistory_Quantity=[]\n",
    "MarketHistory_FillType_Z = [] #ZERO encodecd\n",
    "MarketHistory_OrderType_Z = []\n",
    "\n",
    "OrderBook_buy_Quantity = []\n",
    "OrderBook_buy_Rate = []\n",
    "OrderBook_sell_Quantity = []\n",
    "OrderBook_sell_Rate = []\n",
    "\n",
    "Tick_Ask = []\n",
    "Tick_Bid = []\n",
    "Tick_Last = []\n",
    "\n",
    "Sell_Active_volum  = []\n",
    "Buy_Active_volum   = []\n",
    "Total_Active_Volum = []\n",
    "Historical_Volum   = []\n",
    "\n",
    "Eval_mat_list = []\n",
    "n = 0\n",
    "\n",
    "cp2 =[]\n",
    "p10m2 =[]\n",
    "global cp2 \n",
    "global p10m2 \n",
    "global Prediction_Input\n",
    "\n",
    "markets_data     = {}\n",
    "\n",
    "list_of_market_stat_data = {}\n",
    "\n",
    "market_stat_data ={\"Market\"        : \"cc\",\n",
    "                   \"Tick\"          : \"cc\",\n",
    "                   \"OrderBook\"     : \"cc\",\n",
    "                   \"MarketHistory\" : \"cc\" }\n",
    "\n",
    "\n",
    "\n",
    "market_list = [\n",
    "'USDT-BTC'\n",
    "]\n",
    "\n",
    "testlen = 100\n",
    "\n",
    "'''------------------------------------------model loading ---------------------------------------------------'''\n",
    "#model2m  = load_model('pridic2min.h5')\n",
    "model4m  = load_model('best4mmodel100neurons.hdf5')\n",
    "#model10m = load_model('pridic10min.h5')\n",
    "#model14m = load_model('pridic14min.h5')\n",
    "#model20m = load_model('pridic20min.h5')\n",
    "#model30m = load_model('pridic30min.h5')\n",
    "#model1h  = load_model('pridic1h.h5')\n",
    "#model2h  = load_model('pridic2h.h5')\n",
    "#model3h  = load_model('pridic3h.h5')\n",
    "#model4h  = load_model('pridic4h.h5')\n",
    "#model8h  = load_model('pridic8h.h5')\n",
    "#model16h  = load_model('pridic16h.h5')\n",
    "\n",
    "\n",
    "'''--------------------------------------------Load old data Data------------------------------------------------------'''\n",
    "\n",
    "# load the dataset\n",
    "json_data = []\n",
    "with open(\"../USDT-BTC_Market_Boot_support_Trading_Data.txt\") as file :\n",
    "    for line in file:\n",
    "        json_data.append(json.loads(line))\n",
    "# convert an array of values into a dataset matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''--------------------------------------------Get NEW Data and pedict------------------------------------------------------'''\n",
    "'''    \n",
    "for market in market_list :\n",
    "    markets_data[market] = []\n",
    "'''         \n",
    "              \n",
    "    \n",
    "def Get_market_stat_data():\n",
    "    global MarketHistory_Price\n",
    "    global MarketHistory_Quantity\n",
    "    global MarketHistory_FillType_Z \n",
    "    global MarketHistory_OrderType_Z \n",
    "    global OrderBook_buy_Quantity \n",
    "    global OrderBook_buy_Rate \n",
    "    global OrderBook_sell_Quantity \n",
    "    global OrderBook_sell_Rate\n",
    "    global Tick_Ask\n",
    "    global Tick_Bid \n",
    "    global Tick_Last\n",
    "    global market_stat_data\n",
    "    global Eval_mat_list\n",
    "    global n\n",
    "    global Current_price\n",
    "    global Prediction_UN2m\n",
    "    global Prediction_UN10m\n",
    "    global Prediction_Input\n",
    "    global Prediction_Input_1\n",
    "    global Current_price_1\n",
    "    global testlen\n",
    "    global Sell_Active_volum1 \n",
    "    global Buy_Active_volum1  \n",
    "    global Total_Active_Volum1\n",
    "    global Historical_Volum1\n",
    "    global Sell_Active_volum \n",
    "    global Buy_Active_volum  \n",
    "    global Total_Active_Volum\n",
    "    global Historical_Volum   \n",
    "    global All_Feturs    \n",
    "    global Current_price\n",
    "    global MarketHistory_Feturs\n",
    "    global OrderBook_Feturs\n",
    "    global volum_Feturs\n",
    "    global Curren_Tick_Normalized\n",
    "    global All_Feturs_Normalized \n",
    "    global MarketHistory_Feturs_Normalized\n",
    "    global OrderBook_Feturs_Normalized\n",
    "    global volum_Feturs_Normalized\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(testlen):\n",
    "   \n",
    "        if ( (json_data[i]!= []or None) and\n",
    "             (json_data[i]['Tick'] != []or None ) and \n",
    "             (json_data[i]['OrderBook'] != [] or None) and \n",
    "             (json_data[i]['MarketHistory'] != [] or None) and        \n",
    "             (json_data[i]['MarketHistory']['result'] !=  None) and\n",
    "             (json_data[i]['OrderBook']['result']!=  None )and\n",
    "             (json_data[i]['Tick'] ['result'] != None) and  \n",
    "             (json_data[i]['MarketHistory']['result'] != [] or None) and\n",
    "             (json_data[i]['OrderBook']['result']['buy'] != []or None )and\n",
    "             (json_data[i]['OrderBook']['result']['sell']!= [] or None)and\n",
    "             (json_data[i]['Tick'] ['result'] != [] or  None) and\n",
    "             (json_data[i]['Tick'] ['result'] ['Ask'] !=  [] or  None  ) and\n",
    "             (json_data[i]['Tick'] ['result'] ['Bid'] != [] or None ) and\n",
    "             (json_data[i]['Tick'] ['result'] ['Last']!= [] or None)\n",
    "           ):\n",
    "      \n",
    "            Tick_Ask.append(json_data[i]['Tick'] ['result'] ['Ask'])\n",
    "            Tick_Bid.append(json_data[i]['Tick'] ['result'] ['Bid'])\n",
    "            Tick_Last.append(json_data[i]['Tick'] ['result'] ['Last'])\n",
    "        \n",
    "  \n",
    "            for m in range(len((json_data[1]['OrderBook']['result']['buy']))) :   \n",
    "                OrderBook_buy_Quantity.append(json_data[i]['OrderBook']['result']['buy'][m]['Quantity'])\n",
    "                OrderBook_buy_Rate.append(json_data[i]['OrderBook']['result']['buy'][m]['Rate'])\n",
    "            Buy_Active_volum.append(sum(OrderBook_buy_Rate))    \n",
    "               \n",
    "\n",
    "            for m in range(len((json_data[1]['OrderBook']['result']['sell']))) :\n",
    "                OrderBook_sell_Quantity.append(json_data[i]['OrderBook']['result']['sell'][m]['Quantity'])\n",
    "                OrderBook_sell_Rate.append(json_data[i]['OrderBook']['result']['sell'][m]['Rate']) \n",
    "            Sell_Active_volum.append(sum(OrderBook_sell_Rate))            \n",
    "\n",
    "            for m in range(len((json_data[1]['MarketHistory']['result']))) :                                                                            \n",
    "                MarketHistory_Price.append(json_data[i]['MarketHistory']['result'][m]['Price'])\n",
    "                MarketHistory_Quantity.append(json_data[i]['MarketHistory']['result'][m]['Quantity'])\n",
    "                                              \n",
    "                if (json_data[i]['MarketHistory']['result'][m]['FillType']) == 'PARTIAL_FILL' :\n",
    "                    MarketHistory_FillType_Z.append(0)\n",
    "                elif (json_data[i]['MarketHistory']['result'][m]['FillType']) == 'FILL' :\n",
    "                    MarketHistory_FillType_Z.append(1)\n",
    "                if (json_data[i]['MarketHistory']['result'][m]['OrderType']) == 'BUY' :\n",
    "                    MarketHistory_OrderType_Z.append(0)\n",
    "                elif (json_data[i]['MarketHistory']['result'][m]['OrderType']) == 'SELL' :\n",
    "                    MarketHistory_OrderType_Z.append(1)\n",
    "            Historical_Volum.append(sum(MarketHistory_Quantity))\n",
    "            \n",
    "    prdiction_data_depth = len(Tick_Ask)\n",
    "    if prdiction_data_depth > 700 :\n",
    "        prdiction_data_depth = 700\n",
    "        \n",
    "    print(\"prdiction_data_depth aday is 720 point {} \\n\".format(prdiction_data_depth)) \n",
    "        \n",
    "    Tick_Ask                  = Tick_Ask[(len(Tick_Ask)-prdiction_data_depth):len(Tick_Ask)]\n",
    "    Tick_Bid                  = Tick_Bid[(len(Tick_Bid)-prdiction_data_depth):len(Tick_Bid)]\n",
    "    Tick_Last                 = Tick_Last[(len(Tick_Last)-prdiction_data_depth):len(Tick_Last)]\n",
    "    OrderBook_buy_Rate        = OrderBook_buy_Rate[(len(OrderBook_buy_Rate)-prdiction_data_depth*OrderBookDepth):len(OrderBook_buy_Rate)]\n",
    "    OrderBook_sell_Rate       = OrderBook_sell_Rate[(len(OrderBook_sell_Rate)-prdiction_data_depth*OrderBookDepth):len(OrderBook_sell_Rate)]\n",
    "    OrderBook_buy_Quantity    = OrderBook_buy_Quantity[(len(OrderBook_buy_Quantity)-prdiction_data_depth*OrderBookDepth):len(OrderBook_buy_Quantity)]\n",
    "    OrderBook_sell_Quantity   = OrderBook_sell_Quantity[(len(OrderBook_sell_Quantity)-prdiction_data_depth*OrderBookDepth):len(OrderBook_sell_Quantity)]\n",
    "    MarketHistory_Price       = MarketHistory_Price[(len(MarketHistory_Price)-prdiction_data_depth*MarketHistoryDepth):len(MarketHistory_Price)]\n",
    "    MarketHistory_Quantity    = MarketHistory_Quantity[(len(MarketHistory_Quantity)-prdiction_data_depth*MarketHistoryDepth):len(MarketHistory_Quantity)]\n",
    "    MarketHistory_FillType_Z  = MarketHistory_FillType_Z[(len(MarketHistory_FillType_Z)-prdiction_data_depth*OrderBookDepth):len(MarketHistory_FillType_Z)]\n",
    "    MarketHistory_OrderType_Z = MarketHistory_OrderType_Z[(len(MarketHistory_OrderType_Z)-prdiction_data_depth*OrderBookDepth):len(MarketHistory_OrderType_Z)]\n",
    "    Buy_Active_volum          = Buy_Active_volum[(len(Buy_Active_volum )-prdiction_data_depth):len(Buy_Active_volum )]\n",
    "    Sell_Active_volum         = Sell_Active_volum[(len(Sell_Active_volum)-prdiction_data_depth):len(Sell_Active_volum)]\n",
    "    Historical_Volum          = Historical_Volum[(len(Historical_Volum)-prdiction_data_depth):len(Historical_Volum)]\n",
    "      \n",
    "        \n",
    "    MarketHistory_Price1       =np.reshape( MarketHistory_Price, (int(len(MarketHistory_Price)/depth), depth))\n",
    "    MarketHistory_Quantity1    =np.reshape(MarketHistory_Quantity, (int(len(MarketHistory_Quantity)/depth), depth))\n",
    "    MarketHistory_FillType_Z1  =np.reshape(MarketHistory_FillType_Z, (int(len(MarketHistory_FillType_Z)/depth) ,depth))\n",
    "    MarketHistory_OrderType_Z1 =np.reshape(MarketHistory_OrderType_Z, (int(len(MarketHistory_OrderType_Z)/depth) , depth))\n",
    "    OrderBook_buy_Quantity1    =np.reshape(OrderBook_buy_Quantity, (int(len(OrderBook_buy_Quantity)/depth) , depth))\n",
    "    OrderBook_buy_Rate1        =np.reshape(OrderBook_buy_Rate, (int(len(OrderBook_buy_Rate)/depth) , depth))\n",
    "    OrderBook_sell_Quantity1   =np.reshape(OrderBook_sell_Quantity, (int(len(OrderBook_sell_Quantity)/depth) , depth))\n",
    "    OrderBook_sell_Rate1       =np.reshape(OrderBook_sell_Rate, (int(len(OrderBook_sell_Rate)/depth) , depth))\n",
    "    Tick_Ask1                  =np.reshape(Tick_Ask ,(1,int(len(Tick_Ask))))\n",
    "    Tick_Bid1                  =np.reshape(Tick_Bid ,(1,int(len(Tick_Bid))))\n",
    "    Tick_Last1                 =np.reshape(Tick_Last ,(1,int(len(Tick_Last))))\n",
    "    Buy_Active_volum1          =np.reshape(Buy_Active_volum ,(1,len(Buy_Active_volum)))\n",
    "    Sell_Active_volum1         =np.reshape(Sell_Active_volum ,(1,len(Sell_Active_volum)))\n",
    "    Historical_Volum1          =np.reshape(Historical_Volum ,(1,len(Historical_Volum)))\n",
    "    Total_Active_Volum1        =Buy_Active_volum1 + Sell_Active_volum1     \n",
    "    \n",
    "    All_Feturs = np.concatenate((\n",
    "                       MarketHistory_Price1.T,\n",
    "                       MarketHistory_Quantity1.T,\n",
    "                       MarketHistory_FillType_Z1.T,\n",
    "                       MarketHistory_OrderType_Z1.T,\n",
    "                       OrderBook_buy_Quantity1.T,\n",
    "                       OrderBook_buy_Rate1.T,\n",
    "                       OrderBook_sell_Quantity1.T,\n",
    "                       OrderBook_sell_Rate1.T,\n",
    "                       Tick_Ask1,\n",
    "                       Tick_Bid1,\n",
    "                       Tick_Last1\n",
    "                      ))\n",
    "    Current_price = np.concatenate((\n",
    "                       Tick_Ask1,\n",
    "                       Tick_Bid1,\n",
    "                       Tick_Last1\n",
    "                      ))\n",
    "    MarketHistory_Feturs = np.concatenate((\n",
    "                      MarketHistory_Price1.T,\n",
    "                      MarketHistory_Quantity1.T,\n",
    "                      MarketHistory_FillType_Z1.T,\n",
    "                      MarketHistory_OrderType_Z1.T\n",
    "                     ))\n",
    "\n",
    "    OrderBook_Feturs = np.concatenate((\n",
    "                     OrderBook_buy_Quantity1.T,\n",
    "                     OrderBook_buy_Rate1.T,\n",
    "                     OrderBook_sell_Quantity1.T,\n",
    "                     OrderBook_sell_Rate1.T\n",
    "                    ))\n",
    "\n",
    "    volum_Feturs = np.concatenate((\n",
    "                     Buy_Active_volum1,\n",
    "                     Sell_Active_volum1,\n",
    "                     Total_Active_Volum1,\n",
    "                     Historical_Volum1\n",
    "                    ))\n",
    "    \n",
    "        \n",
    "    #Prediction_Input_1 =Prediction_Input\n",
    "    #Current_price_1 = Current_price\n",
    "        \n",
    "    #Prediction_Input = Prediction_Input[:,:(len(Prediction_Input[1][:])-2)]\n",
    "    #Current_price = Current_price[:,2:]\n",
    "    #a= np.zeros((800,5))\n",
    "    #b= np.zeros((3,5))\n",
    "        \n",
    "    #Prediction_Input = np.insert(Prediction_Input, 0, a, 0)  \n",
    "    #Current_price = np.insert(Current_price, 0, b, 0)  \n",
    "\n",
    "\n",
    "    scalerCurrent_price                   = MinMaxScaler(feature_range=(0, 1))\n",
    "    Curren_Tick_Normalized                = scalerCurrent_price.fit_transform(Current_price)\n",
    "    Curren_Tick_Normalized                = np.reshape(Curren_Tick_Normalized , (Curren_Tick_Normalized.shape[1],1, Curren_Tick_Normalized.shape[0]))    \n",
    "    '''    \n",
    "    scalertraininput = MinMaxScaler(feature_range=(0, 1))\n",
    "    Prediction_Input_Normalized =scalertraininput.fit_transform(Prediction_Input)\n",
    "    \n",
    "    Prediction_Input_Normalized = np.reshape(Prediction_Input_Normalized, (Prediction_Input_Normalized.shape[1],1, Prediction_Input_Normalized.shape[0]))\n",
    "    '''\n",
    "    \n",
    "    scaler_All_Feturs                      = MinMaxScaler(feature_range=(0, 1))\n",
    "    All_Feturs_Normalized                  = scaler_All_Feturs.fit_transform(All_Feturs)\n",
    "    All_Feturs_Normalized                  = np.reshape(All_Feturs_Normalized , (All_Feturs_Normalized .shape[1],1, All_Feturs_Normalized .shape[0]))\n",
    "    \n",
    "    scaler_MarketHistory_Feturs            = MinMaxScaler(feature_range=(0, 1))\n",
    "    MarketHistory_Feturs_Normalized        = scaler_MarketHistory_Feturs.fit_transform(MarketHistory_Feturs)\n",
    "    MarketHistory_Feturs_Normalized        = np.reshape(MarketHistory_Feturs_Normalized, (MarketHistory_Feturs_Normalized.shape[1],1, MarketHistory_Feturs_Normalized.shape[0]))\n",
    "    \n",
    "    scalertr_OrderBook_Feturs              = MinMaxScaler(feature_range=(0, 1))\n",
    "    OrderBook_Feturs_Normalized            = scalertr_OrderBook_Feturs.fit_transform(OrderBook_Feturs)\n",
    "    OrderBook_Feturs_Normalized           = np.reshape(OrderBook_Feturs_Normalized, (OrderBook_Feturs_Normalized.shape[1],1, OrderBook_Feturs_Normalized.shape[0]))\n",
    "    \n",
    "    #scaler_Curren_Tick                     = MinMaxScaler(feature_range=(0, 1))\n",
    "    #Curren_Tick_Normalized                 = scaler_Curren_Tick.fit_transform(Current_price)\n",
    "\n",
    "    scaler_volum_Feturs                    = MinMaxScaler(feature_range=(0, 1))\n",
    "    volum_Feturs_Normalized                = scaler_volum_Feturs.fit_transform(volum_Feturs)\n",
    "    volum_Feturs_Normalized                = np.reshape(volum_Feturs_Normalized , (volum_Feturs_Normalized.shape[1],1, volum_Feturs_Normalized.shape[0]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Prediction2m  = model2m.predict(Prediction_Input_Normalized)\n",
    "    Prediction4m  = model4m.predict([OrderBook_Feturs_Normalized ,Curren_Tick_Normalized ])\n",
    "    #Prediction10m = model10m.predict(Prediction_Input_Normalized)\n",
    "    #Prediction14m = model14m.predict(Prediction_Input_Normalized)\n",
    "    #Prediction20m = model20m.predict(Prediction_Input_Normalized)\n",
    "    #Prediction30m = model30m.predict(Prediction_Input_Normalized)\n",
    "    #Prediction1h  = model1h.predict(Prediction_Input_Normalized)\n",
    "    #Prediction2h  = model2h.predict(Prediction_Input_Normalized)\n",
    "    #Prediction3h  = model3h.predict(Prediction_Input_Normalized)\n",
    "    #Prediction4h  = model4h.predict(Prediction_Input_Normalized)\n",
    "    #Prediction8h  = model8h.predict(Prediction_Input_Normalized)\n",
    "    #Prediction16h = model16h.predict(Prediction_Input_Normalized)\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    #m = Current_price1\n",
    "    #z = Prediction30m\n",
    "        \n",
    "    #Prediction2m = np.reshape(Prediction2m, (Prediction2m.shape[1], Prediction2m.shape[0]))\n",
    "    #Prediction_UN2m =scalerCurrent_price.inverse_transform(Prediction2m)\n",
    "    \n",
    "    Prediction4m = np.reshape(Prediction4m, (Prediction4m.shape[1], Prediction4m.shape[0]))\n",
    "    Prediction_UN4m =scalerCurrent_price.inverse_transform(Prediction4m)\n",
    "    \n",
    "    #Prediction10m = np.reshape(Prediction10m, (Prediction10m.shape[1], Prediction10m.shape[0]))\n",
    "    #Prediction_UN10m =scalerCurrent_price.inverse_transform(Prediction10m)\n",
    "    \n",
    "    #Prediction14m = np.reshape(Prediction14m, (Prediction14m.shape[0], Prediction14m.shape[1]))\n",
    "    #Prediction_UN14m =scalerCurrent_price.inverse_transform(Prediction14m)\n",
    "    \n",
    "    #Prediction20m = np.reshape(Prediction20m, (Prediction20m.shape[0], Prediction20m.shape[1]))\n",
    "    #Prediction_UN20m =scalerCurrent_price.inverse_transform(Prediction20m)\n",
    "    \n",
    "    #Prediction30m = np.reshape(Prediction30m, (Prediction30m.shape[1], Prediction30m.shape[0]))\n",
    "    #Prediction_UN30m =scalerCurrent_price.inverse_transform(Prediction30m)\n",
    "    \n",
    "    #Prediction1h = np.reshape(Prediction1h, (Prediction1h.shape[1], Prediction1h.shape[0]))\n",
    "    #Prediction_UN1h =scalerCurrent_price.inverse_transform(Prediction1h)\n",
    "    \n",
    "    #Prediction2h = np.reshape(Prediction2h, (Prediction2h.shape[0], Prediction2h.shape[1]))\n",
    "    #Prediction_UN2h =scalerCurrent_price.inverse_transform(Prediction2h)\n",
    "    \n",
    "    #Prediction3h = np.reshape(Prediction3h, (Prediction3h.shape[0], Prediction3h.shape[1]))\n",
    "    #Prediction_UN3h =scalerCurrent_price.inverse_transform(Prediction3h)\n",
    "    \n",
    "    #Prediction4h = np.reshape(Prediction4h, (Prediction4h.shape[1], Prediction4h.shape[0]))\n",
    "    #Prediction_UN4h =scalerCurrent_price.inverse_transform(Prediction4h)\n",
    "    \n",
    "    #Prediction8h = np.reshape(Prediction8h, (Prediction8h.shape[1], Prediction8h.shape[0]))\n",
    "    #Prediction_UN8h =scalerCurrent_price.inverse_transform(Prediction8h)\n",
    "    \n",
    "    #Prediction16h = np.reshape(Prediction16h, (Prediction16h.shape[0], Prediction16h.shape[1]))\n",
    "    #Prediction_UN16h =scalerCurrent_price.inverse_transform(Prediction16h)\n",
    "    \n",
    "\n",
    "    #Prediction_UN2m  = np.reshape(Prediction_UN2m,  (Prediction_UN2m.shape[0] , Prediction_UN2m.shape[1])) \n",
    "    #Prediction_UN4m  = np.reshape(Prediction_UN4m,  (Prediction_UN4m.shape[1] , Prediction_UN4m.shape[0]))\n",
    "    #Prediction_UN10m = np.reshape(Prediction_UN10m, (Prediction_UN10m.shape[0], Prediction_UN10m.shape[1]))\n",
    "    #Prediction_UN14m = np.reshape(Prediction_UN14m, (Prediction_UN14m.shape[1], Prediction_UN14m.shape[0]))\n",
    "    #Prediction_UN20m = np.reshape(Prediction_UN20m, (Prediction_UN20m.shape[1], Prediction_UN20m.shape[0]))\n",
    "    #Prediction_UN30m = np.reshape(Prediction_UN30m, (Prediction_UN30m.shape[0], Prediction_UN30m.shape[1]))\n",
    "    #Prediction_UN1h  = np.reshape(Prediction_UN1h,  (Prediction_UN1h.shape[0] , Prediction_UN1h.shape[1]))\n",
    "    #Prediction_UN2h  = np.reshape(Prediction_UN2h,  (Prediction_UN2h.shape[1] , Prediction_UN2h.shape[0]))\n",
    "    #Prediction_UN3h  = np.reshape(Prediction_UN3h,  (Prediction_UN3h.shape[1] , Prediction_UN3h.shape[0]))\n",
    "    #Prediction_UN4h  = np.reshape(Prediction_UN4h,  (Prediction_UN4h.shape[0] , Prediction_UN4h.shape[1]))\n",
    "    #Prediction_UN8h  = np.reshape(Prediction_UN8h,  (Prediction_UN8h.shape[0] , Prediction_UN8h.shape[1]))\n",
    "    #Prediction_UN16h = np.reshape(Prediction_UN16h, (Prediction_UN16h.shape[1], Prediction_UN16h.shape[0]))\n",
    "    #Current_price1 = np.reshape(Current_price1, (Current_price1.shape[1], Current_price1.shape[0]))\n",
    "\n",
    "        \n",
    "    \n",
    "    Eval_mat = np.concatenate((\n",
    "                    Current_price[:,-1],\n",
    "                    Prediction_UN4m[:,-1]\n",
    "                    ))\n",
    "    #print(\"Current_price {} \\n\".format(Current_price))        \n",
    "    #print(\"Eval_mat {} \\n\".format(Eval_mat))\n",
    "    Eval_mat_list= Eval_mat.tolist()\n",
    "    for market in market_list:\n",
    "        with open(\"{}_Market_predictions.txt\".format(market), \"a+\") as market_file :\n",
    "                json.dump(Eval_mat_list, market_file)\n",
    "                market_file.write(\"\\n\") #padding the jason object in file with a newline indcator \"evey opject in his owen line\"\n",
    "                market_file.close()\n",
    "        n = n+1\n",
    "    print(\"#-------prediction no. {} the format is ASK-BID-LAST-----# \\n\".format(n))\n",
    "    print(\"Current price {} \\n\".format(Current_price[:,-1]))\n",
    "    #print(\"prediction+2min {} \\n\".format(Prediction_UN2m[:,-1]))\n",
    "    print(\"prediction+4min {} \\n\".format(Prediction_UN4m[:,-1]))\n",
    "    #print(\"prediction+10min {} \\n\".format(Prediction_UN10m[:,-1]))\n",
    "    #print(\"prediction+30min {} \\n\".format(Prediction_UN30m[:,-1]))\n",
    "    #print(\"prediction+1h {} \\n\".format(Prediction_UN1h[:,-1]))\n",
    "    #print(\"prediction+4h {} \\n\".format(Prediction_UN4h[:,-1]))\n",
    "    #print(\"prediction+8h {} \\n\".format(Prediction_UN8h[:,-1]))\n",
    "    print(\"#-------------------------------------------------------------------------#\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    drow_data_len =testlen\n",
    "    cp2=(Current_price[2,(int(Current_price.shape[1])-drow_data_len):int(Current_price.shape[1])])\n",
    "    p10m2=(Prediction_UN4m[2,(int(Prediction_UN4m.shape[1])-drow_data_len):int(Prediction_UN4m.shape[1])])\n",
    "    #yc =range(len(Current_price[2,:]))\n",
    "    #yp =range(5,len(Prediction_UN10m[2,:]),1)\n",
    "    yc =range(len(cp2)+10)\n",
    "    yp =range(0,len(p10m2)+10,1)        \n",
    "        \n",
    "    p = figure(plot_width=800, plot_height=400)\n",
    "    p.line(yc, cp2, line_width=1)\n",
    "    p.line(yp, p10m2, line_width=1 , line_color=\"red\")\n",
    "    p.circle(yc,cp2, size=2, line_color=\"red\", fill_color=\"orange\", fill_alpha=0.5)\n",
    "    p.circle(yp,p10m2, size=2, line_color=\"navy\", fill_color=\"orange\", fill_alpha=0.5)\n",
    "\n",
    "    show(p)  \n",
    "    \n",
    "    testlen  = testlen + 2\n",
    "'''-----------------------------------------schedular and main entry point--------------------------------------'''\n",
    "\n",
    "Get_market_stat_data()\n",
    "\n",
    "'''\n",
    "for i in range(40):\n",
    "        Get_market_stat_data()\n",
    "        time.sleep(30)\n",
    "\n",
    "\n",
    "'''\n",
    "schedule.every(5).seconds.do(Get_market_stat_data)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Curren_Tick_Normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarketHistory_Feturs = np.concatenate((\n",
    "                      MarketHistory_Price,\n",
    "                      MarketHistory_Quantity,\n",
    "                      MarketHistory_FillType_Z,\n",
    "                      MarketHistory_OrderType_Z\n",
    "                     ),axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarketHistory_Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
