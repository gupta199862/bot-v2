{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LSTM for international airline passengers problem with time step regression framing\n",
    "import json\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "#from pandas import read_csv\n",
    "import math\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(564)\n",
    "# load the dataset\n",
    "json_data = []\n",
    "with open(\"USDT-BTC_Market_Boot_support_Trading_Data.txt\") as file :\n",
    "    for line in file:\n",
    "        json_data.append(json.loads(line))\n",
    "# convert an array of values into a dataset matrix\n",
    "MarketHistory_Price=[]\n",
    "MarketHistory_Quantity=[]\n",
    "MarketHistory_FillType_Z = [] #ZERO encodecd\n",
    "MarketHistory_OrderType_Z = []\n",
    "OrderBook_buy_Quantity = []\n",
    "OrderBook_buy_Rate = []\n",
    "OrderBook_sell_Quantity = []\n",
    "OrderBook_sell_Rate = []\n",
    "Tick_Ask = []\n",
    "Tick_Bid = []\n",
    "Tick_Last = []\n",
    "Sell_Active_volum  = []\n",
    "Buy_Active_volum   = []\n",
    "Total_Active_Volum = []\n",
    "Historical_Volum   = []\n",
    "x= 0  \n",
    "xx=0 \n",
    "depth = 100 \n",
    "for i in range(len(json_data)):\n",
    "   \n",
    "    if ( (json_data[i]!= []or None) and\n",
    "         (json_data[i]['Tick'] != []or None ) and         \n",
    "         (json_data[i]['OrderBook'] != [] or None) and\n",
    "         (json_data[i]['MarketHistory'] != [] or None) and\n",
    "         (json_data[i]['Tick'] ['result'] !=  None ) and\n",
    "         (json_data[i]['OrderBook']['result'] !=  None )and\n",
    "         (json_data[i]['MarketHistory']['result'] !=  None) and\n",
    "         (json_data[i]['MarketHistory']['result'] != [] or None) and\n",
    "         (json_data[i]['OrderBook']['result']['buy'] != []or None )and\n",
    "         (json_data[i]['OrderBook']['result']['sell']!= [] or None)and\n",
    "         (json_data[i]['Tick'] ['result'] != [] or  None) and\n",
    "         (json_data[i]['Tick'] ['result'] ['Ask'] !=  [] or  None  ) and\n",
    "         (json_data[i]['Tick'] ['result'] ['Bid'] != [] or None ) and\n",
    "         (json_data[i]['Tick'] ['result'] ['Last']!= [] or None) \n",
    "       ):\n",
    "      \n",
    "        Tick_Ask.append(json_data[i]['Tick'] ['result'] ['Ask'])\n",
    "        Tick_Bid.append(json_data[i]['Tick'] ['result'] ['Bid'])\n",
    "        Tick_Last.append(json_data[i]['Tick'] ['result'] ['Last'])\n",
    "        \n",
    "  \n",
    "        for m in range(len((json_data[1]['OrderBook']['result']['buy']))) :   \n",
    "            OrderBook_buy_Quantity.append(json_data[i]['OrderBook']['result']['buy'][m]['Quantity'])\n",
    "            OrderBook_buy_Rate.append(json_data[i]['OrderBook']['result']['buy'][m]['Rate'])\n",
    "        Buy_Active_volum.append(sum(OrderBook_buy_Rate))\n",
    "\n",
    "        for m in range(len((json_data[1]['OrderBook']['result']['sell']))) :\n",
    "                OrderBook_sell_Quantity.append(json_data[i]['OrderBook']['result']['sell'][m]['Quantity'])\n",
    "                OrderBook_sell_Rate.append(json_data[i]['OrderBook']['result']['sell'][m]['Rate']) \n",
    "        Sell_Active_volum.append(sum(OrderBook_sell_Rate))\n",
    "\n",
    "\n",
    "        for m in range(len((json_data[1]['MarketHistory']['result']))) :                                                                            \n",
    "                MarketHistory_Price.append(json_data[i]['MarketHistory']['result'][m]['Price'])\n",
    "                MarketHistory_Quantity.append(json_data[i]['MarketHistory']['result'][m]['Quantity'])\n",
    "                                              \n",
    "                if (json_data[i]['MarketHistory']['result'][m]['FillType']) == 'PARTIAL_FILL' :\n",
    "                    MarketHistory_FillType_Z.append(0)\n",
    "                elif (json_data[i]['MarketHistory']['result'][m]['FillType']) == 'FILL' :\n",
    "                    MarketHistory_FillType_Z.append(1)\n",
    "                if (json_data[i]['MarketHistory']['result'][m]['OrderType']) == 'BUY' :\n",
    "                    MarketHistory_OrderType_Z.append(0)\n",
    "                elif (json_data[i]['MarketHistory']['result'][m]['OrderType']) == 'SELL' :\n",
    "                    MarketHistory_OrderType_Z.append(1)\n",
    "        Historical_Volum.append(sum(MarketHistory_Quantity))\n",
    "\n",
    "\n",
    "#MarketHistory_Price       = MarketHistory_Price [::-1]\n",
    "#MarketHistory_Quantity    = MarketHistory_Quantity [::-1]\n",
    "#MarketHistory_FillType_Z  = MarketHistory_FillType_Z [::-1]\n",
    "#MarketHistory_OrderType_Z = MarketHistory_OrderType_Z [::-1]\n",
    "#OrderBook_buy_Quantity    = OrderBook_buy_Quantity [::-1]\n",
    "#OrderBook_buy_Rate        = OrderBook_buy_Rate [::-1]\n",
    "#OrderBook_sell_Quantity   = OrderBook_sell_Quantity [::-1]\n",
    "#OrderBook_sell_Rate       = OrderBook_sell_Rate [::-1]                 \n",
    "#Tick_Ask                  = Tick_Ask [::-1]\n",
    "#Tick_Bid                  = Tick_Bid [::-1]\n",
    "#Tick_Last                 = Tick_Last [::-1]                \n",
    "                    \n",
    "                    \n",
    "v1 = MarketHistory_Price\n",
    "v2 = OrderBook_buy_Rate\n",
    "v3 = OrderBook_sell_Rate\n",
    "v4 = Buy_Active_volum\n",
    "v5 = Total_Active_Volum\n",
    "v6 = Tick_Ask\n",
    "v7 = Tick_Bid\n",
    "v8 = Tick_Last\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "MarketHistory_Price=np.reshape(MarketHistory_Price, (int(len(MarketHistory_Price)/depth),depth))\n",
    "MarketHistory_Quantity=np.reshape(MarketHistory_Quantity, (int(len(MarketHistory_Quantity)/depth),depth))\n",
    "MarketHistory_FillType_Z=np.reshape(MarketHistory_FillType_Z, (int(len(MarketHistory_FillType_Z)/depth),depth))\n",
    "MarketHistory_OrderType_Z=np.reshape(MarketHistory_OrderType_Z, (int(len(MarketHistory_OrderType_Z)/depth),depth))\n",
    "OrderBook_buy_Quantity=np.reshape(OrderBook_buy_Quantity, (int(len(OrderBook_buy_Quantity)/depth),depth))\n",
    "OrderBook_buy_Rate=np.reshape(OrderBook_buy_Rate, (int(len(OrderBook_buy_Rate)/depth),depth))\n",
    "OrderBook_sell_Quantity=np.reshape(OrderBook_sell_Quantity,(int(len(OrderBook_sell_Quantity)/depth),depth))\n",
    "OrderBook_sell_Rate=np.reshape(OrderBook_sell_Rate,(int(len(OrderBook_sell_Rate)/depth),depth))\n",
    "Buy_Active_volum =np.reshape(Buy_Active_volum ,(1,len(Buy_Active_volum)))\n",
    "Sell_Active_volum =np.reshape(Sell_Active_volum ,(1,len(Sell_Active_volum)))\n",
    "Historical_Volum =np.reshape(Historical_Volum ,(1,len(Historical_Volum)))\n",
    "Total_Active_Volum = Buy_Active_volum + Sell_Active_volum\n",
    "Tick_Ask =np.reshape(Tick_Ask ,(1,len(Tick_Ask)))\n",
    "Tick_Bid =np.reshape(Tick_Bid ,(1,len(Tick_Bid)))\n",
    "Tick_Last=np.reshape(Tick_Last ,(1,len(Tick_Last)))\n",
    "\n",
    "\"\"\"\n",
    "Input_Feturs = np.concatenate((\n",
    "                   MarketHistory_Price,\n",
    "                   MarketHistory_Quantity,\n",
    "                   MarketHistory_FillType_Z,\n",
    "                   MarketHistory_OrderType_Z,\n",
    "                   OrderBook_buy_Quantity,\n",
    "                   OrderBook_buy_Rate,\n",
    "                   OrderBook_sell_Quantity,\n",
    "                   OrderBook_sell_Rate\n",
    "                  ))\n",
    "\n",
    "MarketHistory_Feturs = np.concatenate((\n",
    "                   MarketHistory_Price,\n",
    "                   MarketHistory_Quantity,\n",
    "                   MarketHistory_FillType_Z,\n",
    "                   MarketHistory_OrderType_Z\n",
    "                  ))\n",
    "\n",
    "OrderBook_Feturs = np.concatenate((\n",
    "                   OrderBook_buy_Quantity,\n",
    "                   OrderBook_buy_Rate,\n",
    "                   OrderBook_sell_Quantity,\n",
    "                   OrderBook_sell_Rate\n",
    "                  ))\n",
    "\n",
    "volum_Feturs = np.concatenate((\n",
    "                     Buy_Active_volum,\n",
    "                     Sell_Active_volum,\n",
    "                     Total_Active_Volum,\n",
    "                     Historical_Volum\n",
    "                       ))\n",
    "\n",
    "\n",
    "Curren_Tick = np.concatenate((\n",
    "                   Tick_Ask,\n",
    "                   Tick_Bid,\n",
    "                   Tick_Last\n",
    "                  ))\n",
    "\n",
    "All_Feturs = np.concatenate ((\n",
    "               Input_Feturs,\n",
    "               Curren_Tick\n",
    "               ))\n",
    "\n",
    "\n",
    "#np.random.shuffle(Traning_Input)\n",
    "\n",
    "#Traning_Output = Traning_Input[-3:,:]\n",
    "\n",
    "     \n",
    "\n",
    "Curren_Tick1       = Curren_Tick \n",
    "\n",
    "\n",
    "All_Feturs            = All_Feturs          [:,:(len(All_Feturs[1][:])-2)]\n",
    "MarketHistory_Feturs  = MarketHistory_Feturs[:,:(len(MarketHistory_Feturs[1][:])-2)]\n",
    "OrderBook_Feturs      = OrderBook_Feturs    [:,:(len(OrderBook_Feturs[1][:])-2)]\n",
    "volum_Feturs          = volum_Feturs        [:,:(len(volum_Feturs[1][:])-2)]\n",
    "Curren_Tick           = Curren_Tick         [:,:(len(Curren_Tick[1][:])-2)]\n",
    "\n",
    "Tick_to_predict       = Curren_Tick1 [:,2:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# split input into train and test sets\n",
    "train_size = int((All_Feturs.shape[1]) * .92)\n",
    "test_size = All_Feturs.shape[1] - train_size\n",
    "\n",
    "# split output into train and test sets\n",
    "\n",
    "train_All_Feturs          , test_All_Feturs           = All_Feturs[:,0:train_size]          , All_Feturs[:,train_size:]\n",
    "train_MarketHistory_Feturs, test_MarketHistory_Feturs = MarketHistory_Feturs[:,0:train_size], MarketHistory_Feturs[:,train_size:]\n",
    "train_OrderBook_Feturs    , test_OrderBook_Feturs     = OrderBook_Feturs[:,0:train_size]    , OrderBook_Feturs[:,train_size:]\n",
    "train_Curren_Tick         , test_Curren_Tick          = Curren_Tick[:,0:train_size]         , Curren_Tick[:,train_size:]\n",
    "train_volum_Feturs        , test_volum_Feturs         = volum_Feturs[:,0:train_size]        , volum_Feturs[:,train_size:]\n",
    "\n",
    "\n",
    "train_Tick_to_predict     , test_Tick_to_predict      = Tick_to_predict[:,0:train_size]     , Tick_to_predict[:,train_size:]\n",
    "\n",
    "\n",
    "# normalize the dataset\n",
    "\n",
    "scaler_train_All_Feturs                      = MinMaxScaler(feature_range=(0, 1))\n",
    "train_All_Feturs_Normalized                  = scaler_train_All_Feturs.fit_transform(train_All_Feturs)\n",
    "\n",
    "scaler_train_MarketHistory_Feturs            = MinMaxScaler(feature_range=(0, 1))\n",
    "train_MarketHistory_Feturs_Normalized        =scaler_train_MarketHistory_Feturs.fit_transform(train_MarketHistory_Feturs)\n",
    "\n",
    "scalertr_train_OrderBook_Feturs              = MinMaxScaler(feature_range=(0, 1))\n",
    "train_OrderBook_Feturs_Normalized            = scalertr_train_OrderBook_Feturs.fit_transform(train_OrderBook_Feturs)\n",
    "                  \n",
    "scaler_train_Curren_Tick                     = MinMaxScaler(feature_range=(0, 1))\n",
    "train_Curren_Tick_Normalized                 = scaler_train_Curren_Tick.fit_transform(train_Curren_Tick)\n",
    "\n",
    "scaler_train_volum_Feturs                    = MinMaxScaler(feature_range=(0, 1))\n",
    "train_volum_Feturs_Normalized                = scaler_train_volum_Feturs.fit_transform(train_volum_Feturs)\n",
    "\n",
    "\n",
    "scaler_test_All_Feturs                       = MinMaxScaler(feature_range=(0, 1))\n",
    "test_All_Feturs_Normalized                   = scaler_test_All_Feturs.fit_transform(test_All_Feturs)\n",
    "\n",
    "scaler_test_MarketHistory_Feturs             = MinMaxScaler(feature_range=(0, 1))\n",
    "test_MarketHistory_Feturs_Normalized         = scaler_test_MarketHistory_Feturs.fit_transform(test_MarketHistory_Feturs)\n",
    "\n",
    "scaler_test_OrderBook_Feturs                 = MinMaxScaler(feature_range=(0, 1))\n",
    "test_OrderBook_Feturs_Normalized             = scaler_test_OrderBook_Feturs.fit_transform(test_OrderBook_Feturs)\n",
    "\n",
    "scaler_test_Curren_Tick                      = MinMaxScaler(feature_range=(0, 1))\n",
    "test_Curren_Tick_Normalized                  = scaler_test_Curren_Tick.fit_transform(test_Curren_Tick)\n",
    "\n",
    "scaler_test_volum_Feturs                    = MinMaxScaler(feature_range=(0, 1))\n",
    "test_volum_Feturs_Normalized                = scaler_test_volum_Feturs.fit_transform(test_volum_Feturs)\n",
    "\n",
    "\n",
    "\n",
    "scaler_train_Tick_to_predict                 = MinMaxScaler(feature_range=(0, 1))\n",
    "train_Tick_to_predict_Normalized             = scaler_train_Tick_to_predict.fit_transform(train_Tick_to_predict)\n",
    "\n",
    "scaler_test_Tick_to_predict                  = MinMaxScaler(feature_range=(0, 1))\n",
    "test_Tick_to_predict_Normalized              = scaler_test_Tick_to_predict.fit_transform(test_Tick_to_predict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_All_Feturs_Normalized             = np.reshape(train_All_Feturs_Normalized,           (train_All_Feturs_Normalized.shape[1]          ,1, train_All_Feturs_Normalized.shape[0]))\n",
    "train_MarketHistory_Feturs_Normalized   = np.reshape(train_MarketHistory_Feturs_Normalized, (train_MarketHistory_Feturs_Normalized.shape[1],1, train_MarketHistory_Feturs_Normalized.shape[0]))\n",
    "train_OrderBook_Feturs_Normalized       = np.reshape(train_OrderBook_Feturs_Normalized,     (train_OrderBook_Feturs_Normalized.shape[1]    ,1, train_OrderBook_Feturs_Normalized.shape[0]))\n",
    "train_Curren_Tick_Normalized            = np.reshape(train_Curren_Tick_Normalized,          (train_Curren_Tick_Normalized.shape[1]         ,1, train_Curren_Tick_Normalized.shape[0]))\n",
    "train_volum_Feturs_Normalized           = np.reshape(train_volum_Feturs_Normalized,         (train_volum_Feturs_Normalized.shape[1]        ,1, train_volum_Feturs_Normalized.shape[0]))\n",
    "\n",
    "test_All_Feturs_Normalized              = np.reshape(test_All_Feturs_Normalized,            (test_All_Feturs_Normalized.shape[1]           ,1, test_All_Feturs_Normalized.shape[0]))\n",
    "test_MarketHistory_Feturs_Normalized    = np.reshape(test_MarketHistory_Feturs_Normalized,  (test_MarketHistory_Feturs_Normalized.shape[1] ,1, test_MarketHistory_Feturs_Normalized.shape[0]))\n",
    "test_OrderBook_Feturs_Normalized        = np.reshape(test_OrderBook_Feturs_Normalized,      (test_OrderBook_Feturs_Normalized.shape[1]     ,1, test_OrderBook_Feturs_Normalized.shape[0]))\n",
    "test_Curren_Tick_Normalized             = np.reshape(test_Curren_Tick_Normalized,           (test_Curren_Tick_Normalized.shape[1]          ,1, test_Curren_Tick_Normalized.shape[0]))\n",
    "test_volum_Feturs_Normalized            = np.reshape(test_volum_Feturs_Normalized,          (test_volum_Feturs_Normalized.shape[1]         ,1, test_volum_Feturs_Normalized.shape[0]))\n",
    "\n",
    "\n",
    "train_Tick_to_predict_Normalized        = np.reshape(train_Tick_to_predict_Normalized,      (train_Tick_to_predict_Normalized.shape[1],        train_Tick_to_predict_Normalized.shape[0]))\n",
    "test_Tick_to_predict_Normalized         = np.reshape(test_Tick_to_predict_Normalized,       (test_Tick_to_predict_Normalized.shape[1],         test_Tick_to_predict_Normalized.shape[0]))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "del json_data\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(MarketHistory_Price[:,:20]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_Feturs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    \n",
    "v1 = MarketHistory_Price\n",
    "v2 = OrderBook_buy_Rate\n",
    "v3 = OrderBook_sell_Rate\n",
    "v4 = Buy_Active_volum\n",
    "v5 = Total_Active_Volum\n",
    "v6 = Tick_Ask\n",
    "v7 = Tick_Bid\n",
    "v8 = Tick_Last\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(x3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(0,len(x2*10 ),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "def get_truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm(\n",
    "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "\n",
    "colomn_depth = 50\n",
    "sample_length =100\n",
    "normalized_victor_gen  = get_truncated_normal(mean=0.98, sd=0.03, low=0.99, upp=1.01)\n",
    "normalized_victor=normalized_victor_gen.rvs(colomn_depth)\n",
    "normalized_victor = np.array([normalized_victor])\n",
    "normalized_wights_array=(np.repeat(normalized_victor.T,100,axis=1))\n",
    "\n",
    "normalized_buy_wignted_orderbook = OrderBook_buy_Rate[:sample_length ,:colomn_depth]*OrderBook_buy_Quantity[:sample_length ,:colomn_depth] #*(normalized_wights_array.T)\n",
    "normalized_sell_wignted_orderbook = OrderBook_sell_Rate[:sample_length ,:colomn_depth]*OrderBook_sell_Quantity[:sample_length ,:colomn_depth] #*(normalized_wights_array.T)\n",
    "#comon wise summing booth the qunttaty and the normalized_wignted_orderbook\n",
    "\n",
    "normalized_buy_wignted_orderbook_sumed = normalized_buy_wignted_orderbook.sum(axis=1)\n",
    "OrderBook_buy_Quantity_summed = OrderBook_buy_Quantity[:sample_length , :colomn_depth].sum(axis=1)\n",
    "\n",
    "normalized_sell_wignted_orderbook_sumed = normalized_sell_wignted_orderbook.sum(axis=1)\n",
    "OrderBook_sell_Quantity_summed = OrderBook_sell_Quantity[:sample_length , :colomn_depth].sum(axis=1)  \n",
    "\n",
    "expected_price = ((normalized_buy_wignted_orderbook_sumed/OrderBook_buy_Quantity_summed)+(normalized_sell_wignted_orderbook_sumed/OrderBook_sell_Quantity_summed))/(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(normalized_wights_array.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_buy_wignted_orderbook.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.reshape(v3, (3140,100)))[0,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OrderBook_sell_Rate[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_sell_wignted_orderbook_sumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_buy_wignted_orderbook_sumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(normalized_sell_wignted_orderbook_sumed[19]+normalized_buy_wignted_orderbook_sumed[19])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tick_Last[0,:sample_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "# set up some data\n",
    "x1 = expected_price    #v2[:]\n",
    "x2 = Tick_Last[0,:100]    #v6[:]\n",
    "#x3 = v3[:]\n",
    "#x4 = trainoutput[2,:]\n",
    "#x5 = testPredict [1,:]\n",
    "#x6 = testoutputM [1,:]\n",
    "\n",
    "y1 = range(0,len(x1)+1 ,1)\n",
    "#y2 = range(0,len(x2*100 ),100)\n",
    "#y3 = range(0,len(x3 ),1)\n",
    "y2 = range(0,len(x2 ),1)\n",
    "#y5 = range(0,len(x6 ),1)\n",
    "#y6 = range(0,len(x6 ),1)\n",
    "\n",
    "#x5 = x5[5:]\n",
    "\n",
    "# create a new plot with figure\n",
    "p = figure(plot_width=800, plot_height=400)\n",
    "\n",
    "# add both a line and circles on the same plot\n",
    "#p.line(y4, x4, line_width=2,line_color=\"firebrick\")\n",
    "p.line(y1, x1, line_width=1)\n",
    "p.line(y2, x2, line_width=1, line_color=\"red\")\n",
    "#p.line(y2, x2, line_width=1 , line_color=\"red\")\n",
    "#p.line(y3, x3, line_width=1 , line_color=\"navy\")\n",
    "\n",
    "p.circle(y2,x2, size=2, line_color=\"red\", fill_color=\"orange\", fill_alpha=0.5)\n",
    "p.circle(y1,x1, size=2, line_color=\"navy\", fill_color=\"orange\", fill_alpha=0.5)\n",
    "\n",
    "#p.line(y4, x4, line_width=2,line_color=\"orange\")\n",
    "\n",
    "#p.circle(y3,x3, size=10, line_color=\"navy\", fill_color=\"orange\", fill_alpha=0.5)\n",
    "\n",
    "#p.circle(x, z, fill_color=\"white\", size=8)\n",
    "\n",
    "show(p) # show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot( range(len(expected_price)) ,expected_price, 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot( range(len(OrderBook_buy_Rate[0,:])) ,OrderBook_buy_Rate[0,:], 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot( range(len(normalized_wignted_orderbook[0,:])) ,normalized_wignted_orderbook[0,:], 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z= OrderBook_buy_Rate[:,:5].flatten()\n",
    "zbar =\n",
    "a =[]\n",
    "y =[]\n",
    "for i in range(100):\n",
    "    a.append(i)\n",
    "\n",
    "a=np.array([a])\n",
    "yt=(np.repeat(a,(len(z)/100),axis=0)).flatten()\n",
    "xt=(np.repeat(a,(len(z)/100)).flatten()) \n",
    "for i in range(5*100):\n",
    "    y.append(i)\n",
    "y=np.array(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "======================\n",
    "Triangular 3D surfaces\n",
    "======================\n",
    "\n",
    "Plot a 3D surface with a triangular mesh.\n",
    "'''\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Compute z to make the pringle surface.\n",
    "#z = OrderBook_buy_Rate[:].flatten()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "ax.plot_trisurf(y, yt, z, linewidth=0.2, antialiased=True)\n",
    "\n",
    "plt.savefig(\"foo\", dpi=None, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format='svg',\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "========================================\n",
    "Create 2D bar graphs in different planes\n",
    "========================================\n",
    "\n",
    "Demonstrates making a 3D plot which has 2D bar graphs projected onto\n",
    "planes y=0, y=1, etc.\n",
    "\"\"\"\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for c, z in zip(['r', 'g', 'b', 'y'], [30, 20, 10, 0]):\n",
    "    xs = np.arange(20)\n",
    "    ys = np.random.rand(20)\n",
    "\n",
    "    # You can provide either a single color or an array. To demonstrate this,\n",
    "    # the first bar of each set will be colored cyan.\n",
    "    cs = [c] * len(xs)\n",
    "    cs[0] = 'c'\n",
    "    ax.bar(xs, ys, zs=z, zdir='y', color=cs, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OrderBook_buy_Quantity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =((OrderBook_buy_Quantity[1,:]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=range(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OrderBook_buy_Quantity[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OrderBook_buy_Quantity[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OrderBook_buy_Quantity[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =[] \n",
    "for i in range(100):\n",
    "    a.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([a])\n",
    "xt=(np.repeat(a,15579,axis=0)).flatten()\n",
    "yt=(np.repeat(a,15579)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt=(np.repeat(a,15579,axis=0)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt=(np.repeat(a,15579)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len((OrderBook_buy_Quantity[:]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "def get_truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm(\n",
    "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "\n",
    "colomn_depth = 100\n",
    "normalized_victor_gen  = get_truncated_normal(mean=0.98, sd=0.03, low=0.95, upp=1.05)\n",
    "normalized_victor=normalized_victor_gen.rvs(colomn_depth)\n",
    "normalized_victor = np.array([normalized_victor])\n",
    "normalized_wights_array=(np.repeat(normalized_victor.T,15579,axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_wights_array[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "def get_truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm(\n",
    "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = get_truncated_normal(mean=0.98, sd=0.03, low=0.95, upp=1.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=X3.rvs(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.array([xx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt=(np.repeat(xx.T,3,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  [1,2,3,4,5,67,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 100%; }\n",
    "    div#menubar-container     { width: 80%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
