{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM for international airline passengers problem with time step regression framing\n",
    "import json\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "#from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.core.debugger import Tracer\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "# load the dataset\n",
    "json_data = []\n",
    "with open(\"USDT-BTC_Market_Trading_Data.txt\") as file :\n",
    "    for line in file:\n",
    "        json_data.append(json.loads(line))\n",
    "# convert an array of values into a dataset matrix\n",
    "MarketHistory_Price=[]\n",
    "MarketHistory_Quantity=[]\n",
    "MarketHistory_FillType_Z = [] #ZERO encodecd\n",
    "MarketHistory_OrderType_Z = []\n",
    "OrderBook_buy_Quantity = []\n",
    "OrderBook_buy_Rate = []\n",
    "OrderBook_sell_Quantity = []\n",
    "OrderBook_sell_Rate = []\n",
    "Tick_Ask = []\n",
    "Tick_Bid = []\n",
    "Tick_Last = []\n",
    "x= 0  \n",
    "xx=0 \n",
    "depth = 100 \n",
    "for i in range(len(json_data)):\n",
    "   \n",
    "    if ( json_data[i]!= [] and\n",
    "         json_data[i]['Tick'] != [] and         \n",
    "         json_data[i]['OrderBook'] != [] and\n",
    "         json_data[i]['MarketHistory'] != [] and\n",
    "         json_data[i]['MarketHistory']['result'] != [] and\n",
    "         json_data[i]['OrderBook']['result']['buy'] != [] and\n",
    "         json_data[i]['OrderBook']['result']['sell']!= [] and\n",
    "         json_data[i]['Tick'] ['result'] != [] and\n",
    "         json_data[i]['Tick'] ['result'] ['Ask'] != [] and\n",
    "         json_data[i]['Tick'] ['result'] ['Bid'] != [] and\n",
    "         json_data[i]['Tick'] ['result'] ['Last']!= [] and\n",
    "         json_data[i]['Tick'] ['result'] ['Ask'] != None and\n",
    "         json_data[i]['Tick'] ['result'] ['Bid'] != None and\n",
    "         json_data[i]['Tick'] ['result'] ['Last']!= None\n",
    "             \n",
    "       ) :\n",
    "      \n",
    "        Tick_Ask.append(json_data[i]['Tick'] ['result'] ['Ask'])\n",
    "        Tick_Bid.append(json_data[i]['Tick'] ['result'] ['Bid'])\n",
    "        Tick_Last.append(json_data[i]['Tick'] ['result'] ['Last'])\n",
    "        \n",
    "  \n",
    "        for m in range(len((json_data[1]['OrderBook']['result']['buy']))) :   \n",
    "            OrderBook_buy_Quantity.append(json_data[i]['OrderBook']['result']['buy'][m]['Quantity'])\n",
    "            OrderBook_buy_Rate.append(json_data[i]['OrderBook']['result']['buy'][m]['Rate'])\n",
    "            #xx=xx+1\n",
    "            #print(\"dedata 1 no{}\".format(xx))\n",
    "\n",
    "\n",
    "        for m in range(len((json_data[1]['OrderBook']['result']['sell']))) :\n",
    "                OrderBook_sell_Quantity.append(json_data[i]['OrderBook']['result']['sell'][m]['Quantity'])\n",
    "                OrderBook_sell_Rate.append(json_data[i]['OrderBook']['result']['sell'][m]['Rate']) \n",
    "\n",
    "\n",
    "        for m in range(len((json_data[1]['MarketHistory']['result']))) :                                                                            \n",
    "                MarketHistory_Price.append(json_data[i]['MarketHistory']['result'][m]['Price'])\n",
    "                MarketHistory_Quantity.append(json_data[i]['MarketHistory']['result'][m]['Quantity'])\n",
    "                                              \n",
    "                if (json_data[i]['MarketHistory']['result'][m]['FillType']) == 'PARTIAL_FILL' :\n",
    "                    MarketHistory_FillType_Z.append(0)\n",
    "                elif (json_data[i]['MarketHistory']['result'][m]['FillType']) == 'FILL' :\n",
    "                    MarketHistory_FillType_Z.append(1)\n",
    "                if (json_data[i]['MarketHistory']['result'][m]['OrderType']) == 'BUY' :\n",
    "                    MarketHistory_OrderType_Z.append(0)\n",
    "                elif (json_data[i]['MarketHistory']['result'][m]['OrderType']) == 'SELL' :\n",
    "                    MarketHistory_OrderType_Z.append(1)\n",
    "\n",
    "\n",
    "MarketHistory_Price       = MarketHistory_Price [::-1]\n",
    "MarketHistory_Quantity    = MarketHistory_Quantity [::-1]\n",
    "MarketHistory_FillType_Z  = MarketHistory_FillType_Z [::-1]\n",
    "MarketHistory_OrderType_Z = MarketHistory_OrderType_Z [::-1]\n",
    "OrderBook_buy_Quantity    = OrderBook_buy_Quantity [::-1]\n",
    "OrderBook_buy_Rate        = OrderBook_buy_Rate [::-1]\n",
    "OrderBook_sell_Quantity   = OrderBook_sell_Quantity [::-1]\n",
    "OrderBook_sell_Rate       = OrderBook_sell_Rate [::-1]                 \n",
    "Tick_Ask                  = Tick_Ask [::-1]\n",
    "Tick_Bid                  = Tick_Bid [::-1]\n",
    "Tick_Last                 = Tick_Last [::-1]                \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "MarketHistory_Price=np.reshape(MarketHistory_Price, (depth,int(len(MarketHistory_Price)/depth)))\n",
    "MarketHistory_Quantity=np.reshape(MarketHistory_Quantity, (depth,int(len(MarketHistory_Quantity)/depth)))\n",
    "MarketHistory_FillType_Z=np.reshape(MarketHistory_FillType_Z, (depth,int(len(MarketHistory_FillType_Z)/depth)))\n",
    "MarketHistory_OrderType_Z=np.reshape(MarketHistory_OrderType_Z, (depth,int(len(MarketHistory_OrderType_Z)/depth)))\n",
    "OrderBook_buy_Quantity=np.reshape(OrderBook_buy_Quantity, (depth,int(len(OrderBook_buy_Quantity)/depth)))\n",
    "OrderBook_buy_Rate=np.reshape(OrderBook_buy_Rate, (depth,int(len(OrderBook_buy_Rate)/depth)))\n",
    "OrderBook_sell_Quantity=np.reshape(OrderBook_sell_Quantity, (depth,int(len(OrderBook_sell_Quantity)/depth)))\n",
    "OrderBook_sell_Rate=np.reshape(OrderBook_sell_Rate, (depth,int(len(OrderBook_sell_Rate)/depth)))\n",
    "Tick_Ask =np.reshape(Tick_Ask ,(1,len(Tick_Ask)))\n",
    "Tick_Bid =np.reshape(Tick_Bid ,(1,len(Tick_Bid)))\n",
    "Tick_Last=np.reshape(Tick_Last ,(1,len(Tick_Last)))\n",
    "\n",
    "\n",
    "\n",
    "Traning_Input = np.concatenate((\n",
    "                   MarketHistory_Price,\n",
    "                   MarketHistory_Quantity,\n",
    "                   MarketHistory_FillType_Z,\n",
    "                   MarketHistory_OrderType_Z,\n",
    "                   OrderBook_buy_Quantity,\n",
    "                   OrderBook_buy_Rate,\n",
    "                   OrderBook_sell_Quantity,\n",
    "                   OrderBook_sell_Rate\n",
    "                  ))\n",
    "Traning_Output = np.concatenate((\n",
    "                   Tick_Ask,\n",
    "                   Tick_Bid,\n",
    "                   Tick_Last\n",
    "                  ))\n",
    "\n",
    "# split input into train and test sets\n",
    "train_size = int((Traning_Input.shape[1]) * .7)\n",
    "test_size = Traning_Input.shape[1] - train_size\n",
    "traininput, testinput = Traning_Input[:,0:train_size], Traning_Input[:,train_size:]\n",
    "# split output into train and test sets\n",
    "trainoutput , testoutput = Traning_Output[:,0:train_size], Traning_Output[:,train_size:]\n",
    "\n",
    "\n",
    "# normalize the dataset\n",
    "\n",
    "scalertraininput = MinMaxScaler(feature_range=(0, 1))\n",
    "Traning_Input_Normalized =scalertraininput.fit_transform(traininput)\n",
    "\n",
    "scalertestinput = MinMaxScaler(feature_range=(0, 1))\n",
    "Test_Input_Normalized =scalertestinput.fit_transform(testinput)\n",
    "\n",
    "scalertrainoutput = MinMaxScaler(feature_range=(0, 1))\n",
    "Traning_Output_Normalized =scalertrainoutput.fit_transform(trainoutput)\n",
    "                  \n",
    "scalertestoutput = MinMaxScaler(feature_range=(0, 1))\n",
    "Test_Output_Normalized =scalertestoutput.fit_transform(testoutput)\n",
    "\n",
    "\n",
    "\n",
    "traininputM = np.reshape(Traning_Input_Normalized, (Traning_Input_Normalized.shape[1],1, Traning_Input_Normalized.shape[0]))\n",
    "testinputM = np.reshape(Test_Input_Normalized, (Test_Input_Normalized.shape[1],1, Test_Input_Normalized.shape[0]))\n",
    "trainoutputM = np.reshape(Traning_Output_Normalized, (Traning_Output_Normalized.shape[1], Traning_Output_Normalized.shape[0]))\n",
    "testoutputM = np.reshape(Test_Output_Normalized, (Test_Output_Normalized.shape[1], Test_Output_Normalized.shape[0]))\n",
    "\n",
    "'''\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(803, input_shape=(1,803)))\n",
    "model.add(Dense(803))\n",
    "model.add(Dense(3))\n",
    "'''\n",
    "\n",
    "\n",
    "#This returns a tensor\n",
    "inputs = Input(shape=(1,depth*8))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = LSTM(depth*8, input_shape=(1,depth*8),return_sequences=True,dropout_W=0.2)(inputs)\n",
    "x = LSTM(800,dropout_W=0.3)(x)\n",
    "x = Dense(800)(x)\n",
    "x = Dense(100)(x)\n",
    "predictions = Dense(3)(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "'''\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(traininput, trainoutput , batch_size=3, epochs=100, verbose=1 )\n",
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "# make predictions\n",
    "trainPredict = model.predict(traininput)\n",
    "testPredict = model.predict(testinput)\n",
    "# invert predictions\n",
    "trainPredict = scalerinput.inverse_transform(trainPredict)\n",
    "trainY = scaleroutput.inverse_transform([trainoutput])\n",
    "testPredict = scalerinput.inverse_transform(testPredict)\n",
    "testY = scaleroutput.inverse_transform([testoutput])\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(datan\n",
    "nset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.empty((traininput.shape[0],(traininput.shape[1]-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=traininput[:,:(len(traininput[1][:])-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=traininput[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininput_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininput.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traininput[1][:(len(traininput[1][:])-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarketHistory_FillType_Z[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up some data\n",
    "#x1 = Traning_Output1[:,1]\n",
    "trainPredict1 = np.reshape(trainPredict, (trainPredict.shape[1], trainPredict.shape[0]))\n",
    "testPredict1 = np.reshape(testPredict, (testPredict.shape[1], testPredict.shape[0]))\n",
    "trainPredict1=trainPredict1[::-1]\n",
    "x=np.vstack((trainPredict1,testPredict1))\n",
    "x = np.reshape(x, (x.shape[1], x.shape[0]))\n",
    "\n",
    "x5=x[2,:]\n",
    "x2 = trainPredict[2,:]\n",
    "x3 = Traning_Output[2,:]\n",
    "x4 = trainoutput[2,:]\n",
    "y1 = range(len(x1 ))\n",
    "y2 = range(len(x2 ))\n",
    "y3 = range(len(x3 ))\n",
    "y4 = range(len(x4 ))\n",
    "y5 = range(len(x5 ))\n",
    "\n",
    "\n",
    "\n",
    "# create a new plot with figure\n",
    "p = figure(plot_width=1500, plot_height=900)\n",
    "\n",
    "# add both a line and circles on the same plot\n",
    "p.line(y5, x5, line_width=2,line_color=\"firebrick\")\n",
    "#p.line(y1, x1, line_width=2)\n",
    "p.circle(y3,x3, size=2, line_color=\"navy\", fill_color=\"orange\", fill_alpha=0.5)\n",
    "#p.line(y4, x4, line_width=2,line_color=\"orange\")\n",
    "#p.circle(y2,x2, size=10, line_color=\"navy\", fill_color=\"orange\", fill_alpha=0.5)\n",
    "p.line(y2, x2, line_width=2,line_color=\"orange\")\n",
    "\n",
    "\n",
    "\n",
    "show(p) # show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx=trainPredict.vstack(testPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = np.reshape(trainPredict, (trainPredict.shape[1], trainPredict.shape[0]))\n",
    "testPredict = np.reshape(testPredict, (testPredict.shape[1], testPredict.shape[0]))\n",
    "x=np.vstack((trainPredict,testPredict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.vstack((trainPredict,testPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=np.vstack((v,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=v[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc.vstack(testPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(MarketHistory_Price)/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Traning_Input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Traning_Output1 = np.reshape(Traning_Output, (Traning_Output.shape[1], Traning_Output.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Traning_Output1[100,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict[100,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict=trainPredict[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up some data\n",
    "#x1 = Traning_Output1[:,1]\n",
    "x2 = trainPredict[:,1]\n",
    "x3 = Traning_Output[2,:]\n",
    "x4 = trainoutput[2,:]\n",
    "y1 = range(len(x1 ))\n",
    "y2 = range(len(x2 ))\n",
    "y3 = range(len(x3 ))\n",
    "y4 = range(len(x4 ))\n",
    "\n",
    "\n",
    "# create a new plot with figure\n",
    "p = figure(plot_width=800, plot_height=400)\n",
    "\n",
    "# add both a line and circles on the same plot\n",
    "p.line(y4, x4, line_width=2,line_color=\"firebrick\")\n",
    "p.line(y1, x1, line_width=2)\n",
    "p.circle(y3,x3, size=2, line_color=\"navy\", fill_color=\"orange\", fill_alpha=0.5)\n",
    "p.line(y4, x4, line_width=2,line_color=\"orange\")\n",
    "\n",
    "p.circle(y3,x3, size=10, line_color=\"navy\", fill_color=\"orange\", fill_alpha=0.5)\n",
    "\n",
    "#p.circle(x, z, fill_color=\"white\", size=8)\n",
    "\n",
    "show(p) # show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(traininputM, trainoutputM , batch_size=2000, epochs=100, verbose=1 ,  validation_data=(testinputM, testoutputM ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traininputM[:3,0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(traininputM)\n",
    "testPredict = model.predict(testinputM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = np.reshape(trainPredict, (trainoutput.shape[0], trainoutput.shape[1]))\n",
    "testPredict = np.reshape(testPredict, (testoutput.shape[0], testoutput.shape[1]))\n",
    "trainoutputM = np.reshape(trainoutputM, (trainoutput.shape[0], trainoutput.shape[1]))\n",
    "testoutputM = np.reshape(testoutputM, (testoutput.shape[0], testoutput.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict=scalertrainoutput.inverse_transform(trainoutputM)\n",
    "testPredict=scalertestoutput.inverse_transform(testPredict)\n",
    "trainoutputM=scalertrainoutput.inverse_transform(trainoutputM)\n",
    "testoutputM=scalertestoutput.inverse_transform(testoutputM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = np.reshape(trainPredict, (trainPredict.shape[1], trainPredict.shape[0]))\n",
    "testPredict = np.reshape(testPredict, (testPredict.shape[1], testPredict.shape[0]))\n",
    "trainoutputM = np.reshape(trainoutputM, (trainoutputM.shape[1], trainoutputM.shape[0]))\n",
    "testoutputM = np.reshape(testoutputM, (testoutputM.shape[1], testoutputM.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(trainPredict[1,:]*1000000)\n",
    "plt.plot(trainoutputM[1,:]*10000, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(testPredict[2,:])\n",
    "plt.plot(testoutputM[2,:] , 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(testoutputM[:,2] , 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict=scalertrainoutput.inverse_transform(trainoutputM)\n",
    "testPredict=scalertrainoutput.inverse_transform(testPredict)\n",
    "trainoutputM=scalertrainoutput.inverse_transform(trainoutputM)\n",
    "testoutputM=scalertestoutput.inverse_transform(testoutputM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainoutputM*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininput1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Traning_Input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininput1 = np.reshape(traininput1, (traininput.shape[0],traininput.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininput1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerinput = MinMaxScaler(feature_range=(0, 1,))\n",
    "Traning_Input_Normalized1=scalerinput.fit_transform(traininput1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerinput.inverse_transform(Traning_Input_Normalized1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininput1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(trainoutput[:,1]*1000 , 'r*-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = np.hsplit(x,[0,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " b = np.hstack((splits[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len((json_data[200]['OrderBook']['result']['sell'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from keras.models import model_from_yaml\n",
    "import keras.models\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(json_data[1]['OrderBook']['result']['buy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
